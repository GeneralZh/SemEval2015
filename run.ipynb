{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import spatial\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.metrics import euclidean_distances\n",
    "import sys, codecs\n",
    "from pyemd import emd\n",
    "import sklearn.metrics\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_file = \"/home/tongwang/data/word2vec/glove.42B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_tfidf_cosine(src, dst):\n",
    "    ##read sentence pairs to two lists\n",
    "    b1 = []\n",
    "    b2 = []\n",
    "    lines = 0\n",
    "    with open(src) as p:\n",
    "        for i, line in enumerate(p):\n",
    "            s = line.split('\\t')\n",
    "            b1.append(s[0])\n",
    "            b2.append(s[1][:-1]) #remove \\n\n",
    "            lines = i + 1\n",
    "    # vectorizer = TfidfVectorizer(stop_words = 'english') #if remove stop words, some sentence becomes 0\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit_transform(b1 + b2)\n",
    "    b1_vecs = vectorizer.transform(b1).todense()\n",
    "    b2_vecs = vectorizer.transform(b2).todense()\n",
    "    res = [round(5*(1 - spatial.distance.cosine(b1_vecs[i], b2_vecs[i])),2) for i in range(lines)]\n",
    "    with open(dst, 'w') as thefile:\n",
    "        thefile.write(\"\\n\".join(str(i) for i in res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_tfidf_cosine('./dataset/STS.input.answers-forums.txt', './dataset/sys.forum')\n",
    "score_tfidf_cosine('./dataset/STS.input.answers-students.txt', './dataset/sys.students')\n",
    "score_tfidf_cosine('./dataset/STS.input.belief.txt', './dataset/sys.belief')\n",
    "score_tfidf_cosine('./dataset/STS.input.headlines.txt', './dataset/sys.headlines')\n",
    "score_tfidf_cosine('./dataset/STS.input.images.txt', './dataset/sys.images')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
